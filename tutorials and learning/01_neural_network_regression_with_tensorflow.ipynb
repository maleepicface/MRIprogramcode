{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab82e536",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem, but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54044c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e356ab",
   "metadata": {},
   "source": [
    "## Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daf941ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15cf7ad3f70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc50e44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404a6bf",
   "metadata": {},
   "source": [
    "## Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "539276a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552616aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b8adcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 6.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67b98750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a4f970d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d98d6a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bf964ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our NumPy arrays into tensors with dtype float32\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37b7ff65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e1b3b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15cf7afc280>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e24d8",
   "metadata": {},
   "source": [
    "## Steps in modeling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns it's learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f3c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 501us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 501us/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 500us/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cf7e4ebe0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "or: \n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\"\"\"\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "             optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a2e6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7b10c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5e2e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.71602]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918b0b9",
   "metadata": {},
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, or change the activation function of each layer\n",
    "2. **Compiling a model** - here we might change the optimization function  or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for some **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6417ac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 501us/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cf93b75b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model (this time we'll train for longer)\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc25a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "160ae4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if our model's prediction has improved...\n",
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebf53afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.5736 - mae: 10.5736\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.1236 - mae: 10.1236\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 9.6736 - mae: 9.6736\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 9.2236 - mae: 9.2236\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 8.7736 - mae: 8.7736\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 8.3236 - mae: 8.3236\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.8736 - mae: 7.8736\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.4236 - mae: 7.4236\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9736 - mae: 6.9736\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.8250 - mae: 6.8250\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.7706 - mae: 6.7706\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.9023 - mae: 6.9023\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9798 - mae: 6.9798\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 7.0115 - mae: 7.0115\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.0041 - mae: 7.0041\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9629 - mae: 6.9629\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.7967 - mae: 6.7967\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.6786 - mae: 6.6786\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.5410 - mae: 6.5410\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.3862 - mae: 6.3862\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.2161 - mae: 6.2161\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.0324 - mae: 6.0324\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.9317 - mae: 5.9317\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.8711 - mae: 5.8711\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.8089 - mae: 5.8089\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.7619 - mae: 5.7619\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 509us/step - loss: 5.7609 - mae: 5.7609\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.7017 - mae: 5.7017\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.5917 - mae: 5.5917\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.4656 - mae: 5.4656\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3926 - mae: 5.3926\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3197 - mae: 5.3197\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.2467 - mae: 5.2467\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1738 - mae: 5.1738\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.1009 - mae: 5.1009\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.0279 - mae: 5.0279\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.9770 - mae: 4.9770\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.9214 - mae: 4.9214\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.8387 - mae: 4.8387\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.7472 - mae: 4.7472\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.6789 - mae: 4.6789\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.6100 - mae: 4.6100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.5405 - mae: 4.5405\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.4706 - mae: 4.4706\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.4002 - mae: 4.4002\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.3295 - mae: 4.3295\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.2584 - mae: 4.2584\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.1869 - mae: 4.1869\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.1152 - mae: 4.1152\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.0432 - mae: 4.0432\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.9710 - mae: 3.9710\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8986 - mae: 3.8986\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.8259 - mae: 3.8259\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.7531 - mae: 3.7531\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.6802 - mae: 3.6802\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.6071 - mae: 3.6071\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.5339 - mae: 3.5339\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.4605 - mae: 3.4605\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3871 - mae: 3.3871\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3135 - mae: 3.3135\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.2399 - mae: 3.2399\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1662 - mae: 3.1662\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.0924 - mae: 3.0924\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.0220 - mae: 3.0220\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.9468 - mae: 2.9468\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.8747 - mae: 2.8747\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8024 - mae: 2.8024\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7299 - mae: 2.7299\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 2.6571 - mae: 2.6571\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.5841 - mae: 2.5841\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5110 - mae: 2.5110\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.4377 - mae: 2.4377\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.3642 - mae: 2.3642\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 2.2906 - mae: 2.2906\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.2169 - mae: 2.2169\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.1431 - mae: 2.1431\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.0692 - mae: 2.0692\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 2.0054 - mae: 2.0054\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 1.9234 - mae: 1.9234\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.8512 - mae: 1.8512\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.7788 - mae: 1.7788\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.7061 - mae: 1.7061\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 1.6331 - mae: 1.6331\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 1.5600 - mae: 1.5600\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.4867 - mae: 1.4867\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 500us/step - loss: 1.4132 - mae: 1.4132\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.3395 - mae: 1.3395\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.2657 - mae: 1.2657\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.1918 - mae: 1.1918\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1178 - mae: 1.1178\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.0437 - mae: 1.0437\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.9695 - mae: 0.9695\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.8952 - mae: 0.8952\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.8208 - mae: 0.8208\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.7464 - mae: 0.7464\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.6828 - mae: 0.6828\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.5997 - mae: 0.5997\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5291 - mae: 0.5291\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.4521 - mae: 0.4521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cf960e130>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([ # homework\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.1),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fd35c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.497076]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17]) # end of homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "600634cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 14.2261 - mae: 14.2261\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 13.5328 - mae: 13.5328\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.8450 - mae: 12.8450\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 12.1611 - mae: 12.1611\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.4786 - mae: 11.4786\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.7953 - mae: 10.7953\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 10.1084 - mae: 10.1084\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 9.4153 - mae: 9.4153\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7133 - mae: 8.7133\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.9998 - mae: 7.9998\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2724 - mae: 7.2724\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6391 - mae: 6.6391\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6431 - mae: 6.6431\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.9208 - mae: 6.9208\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.0980 - mae: 7.0980\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 7.2570 - mae: 7.2570\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 7.2611 - mae: 7.2611\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1037 - mae: 7.1037\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.8542 - mae: 6.8542\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 6.6416 - mae: 6.6416\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.4073 - mae: 6.4073\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 6.1556 - mae: 6.1556\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.9512 - mae: 5.9512\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.9037 - mae: 5.9037\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.8553 - mae: 5.8553\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9016 - mae: 5.9016\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.8472 - mae: 5.8472\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.7049 - mae: 5.7049\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.5259 - mae: 5.5259\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.4255 - mae: 5.4255\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.3213 - mae: 5.3213\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.2131 - mae: 5.2131\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 5.1472 - mae: 5.1472\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 5.0909 - mae: 5.0909\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.9926 - mae: 4.9926\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.8552 - mae: 4.8552\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.6821 - mae: 4.6821\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.5740 - mae: 4.5740\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 4.4584 - mae: 4.4584\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.3351 - mae: 4.3351\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.2039 - mae: 4.2039\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 4.0647 - mae: 4.0647\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.9171 - mae: 3.9171\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7610 - mae: 3.7610\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.5961 - mae: 3.5961\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.4221 - mae: 3.4221\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2387 - mae: 3.2387\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.0457 - mae: 3.0457\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.8428 - mae: 2.8428\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.6857 - mae: 2.6857\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.4548 - mae: 2.4548\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 2.2068 - mae: 2.2068\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.9829 - mae: 1.9829\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.8204 - mae: 1.8204\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1.4857 - mae: 1.4857\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 1.2132 - mae: 1.2132\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9993 - mae: 0.9993\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.7101 - mae: 0.7101\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3594 - mae: 0.3594\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1118 - mae: 0.1118\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3994 - mae: 0.3994\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.5249 - mae: 0.5249\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.8002 - mae: 0.8002\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.9110 - mae: 0.9110\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8892 - mae: 0.8892\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9457 - mae: 0.9457\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.8913 - mae: 0.8913\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.8768 - mae: 0.8768\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.7506 - mae: 0.7506\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.6897 - mae: 0.6897\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.5674 - mae: 0.5674\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.3382 - mae: 0.3382\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1770 - mae: 0.1770\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1846 - mae: 0.1846\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.2042 - mae: 0.2042\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.4884 - mae: 0.4884\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.5454 - mae: 0.5454\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.4443 - mae: 0.4443\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5707 - mae: 0.5707\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.6051 - mae: 0.6051\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.4780 - mae: 0.4780\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.3399 - mae: 0.3399\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.3067 - mae: 0.3067\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1018 - mae: 0.1018\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.2650 - mae: 0.2650\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.2374 - mae: 0.2374\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 500us/step - loss: 0.3402 - mae: 0.3402\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4551 - mae: 0.4551\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.3949 - mae: 0.3949\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2212 - mae: 0.2212\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2634 - mae: 0.2634\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0835 - mae: 0.0835\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2379 - mae: 0.2379\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1928 - mae: 0.1928\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2699 - mae: 0.2699\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.3601 - mae: 0.3601\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2943 - mae: 0.2943\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.1065 - mae: 0.1065\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1595 - mae: 0.1595\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0556 - mae: 0.0556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cf98c6a00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (this time with an extra hidden layer with 100 hiden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=[\"mae\"],\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5198a54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38344581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.138466]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to make a prediction\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955bf7f",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building neural networks is:\n",
    "\n",
    "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48ee4f",
   "metadata": {},
   "source": [
    "When it comes to evaluation... there are 3 words you should memorize:\n",
    "\n",
    "> \"Visualize, visualize, visualize\"\n",
    "\n",
    "It's a good idea to visualize:\n",
    "* The data - what data are we working with? What does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9b15f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94a8d893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "y = X+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec95f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15cfa9f1fa0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31e755",
   "metadata": {},
   "source": [
    "### The 3 sets...\n",
    "* **The training set** - the model learns from this data, which is typically 70-80% of the total data you have available\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available\n",
    "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically around 10-15% of the total data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "becde780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4792700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23d1a5",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now we've got our data in training and test sets... let's visualize again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee87b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15cfa973040>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train,y_train, c=\"b\", label=\"Training data\") # our model will learn on this\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test,y_test,c=\"g\",label=\"Testing data\") # want our model to be able to predict this (given X what's y?)\n",
    "# Show a legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ae4eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at how to build a neural network for our data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "# model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5dbc8",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faf6adc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \"\"\"\n\u001b[0;32m   2350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2352\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f21afd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b10bb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument in the first layer\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"model_1\")\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecc6c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa347a",
   "metadata": {},
   "source": [
    "* Total params - total number of parameters in the model\n",
    "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
    "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learn patterns or parameters from other models during **transfer learning**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf3ab5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cfaa71cd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35a1a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "883b2939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971acf80",
   "metadata": {},
   "source": [
    "### Visualizing our model's predictions\n",
    "\n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
    "\n",
    "Often you'll see this in the form of 'y_test' or 'y_true' versus 'y_pred' (ground truth versus your model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e63bc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFAAD2670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de6a011a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f8951",
   "metadata": {},
   "source": [
    "**Note:** If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48e9dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a plotting function\n",
    "def plot_predictions(train_data=X_train,\n",
    "                    train_labels=y_train,\n",
    "                    test_data=X_test,\n",
    "                    test_labels=y_test,\n",
    "                    predictions=y_pred):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions to ground truths labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data,train_labels,c=\"b\",label=\"Training data\")\n",
    "    # Plot testing data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "    # Plot model's predictions in red\n",
    "    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "    # Show the legend\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a16ab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(train_data=X_train,\n",
    "                train_labels=y_train,\n",
    "                test_data=X_test,\n",
    "                test_labels=y_test,\n",
    "                predictions=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2fb04",
   "metadata": {},
   "source": [
    "### Evaluating our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
    "\n",
    "Since we're working on a regression, two of the main metrics:\n",
    "* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions\"\n",
    "* MSE - mean square error, \"square the average errors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "344187d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1969 - mae: 3.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.196941375732422, 3.196941375732422]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf8e1050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.558252 , 14.1160555, 11.708944 , 10.336931 , 10.       ,\n",
       "       10.698161 , 12.447113 , 15.332995 , 19.253971 , 23.84169  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=tf.constant(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50c54e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56442f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51ea2004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "        93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "808dfb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute error (actually this time)\n",
    "mae = tf.metrics.mean_absolute_error(y_test,tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0bf9c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.070127>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean square error\n",
    "tf.metrics.mean_squared_error(y_test,tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9e40ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some functions to reuse MAE and MSE\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f019a9",
   "metadata": {},
   "source": [
    "### Running experiments to improve our model\n",
    "\n",
    "'''\n",
    "Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> ...\n",
    "\n",
    "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
    "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer. \n",
    "3. Train for longer - give your model more of a chance to find patterns in the data\n",
    "\n",
    "Let's do 3 modeling experiments:\n",
    "\n",
    "1. 'model_1' - same as the original model, 1 layer, trained for 100 epochs\n",
    "2. 'model_2' - 2 layers, trained for 100 epochs\n",
    "3. 'model_3' - 2 layers, trained for 500 epochs\n",
    "\n",
    "**Build model_1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc19fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 751us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 500us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 751us/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cfaf76220>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "982e80bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFB0943A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7bff76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[53.57109 ],\n",
       "        [57.05633 ],\n",
       "        [60.541573],\n",
       "        [64.02681 ],\n",
       "        [67.512054],\n",
       "        [70.99729 ],\n",
       "        [74.48254 ],\n",
       "        [77.96777 ],\n",
       "        [81.45301 ],\n",
       "        [84.938255]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([53.57109 , 57.05633 , 60.541573, 64.02681 , 67.512054, 70.99729 ,\n",
       "        74.48254 , 77.96777 , 81.45301 , 84.938255], dtype=float32)>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_preds_1), tf.squeeze(y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58afc074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test,y_preds_1)\n",
    "mse_1=mse(y_test,y_preds_1)\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10c7a4",
   "metadata": {},
   "source": [
    "**Build 'model_2'**\n",
    "\n",
    "* 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3e22314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 73.0019 - mse: 7955.5845\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.5325 - mse: 483.7136\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 20.4862 - mse: 612.8414\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.1871 - mse: 230.7354\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 14.5492 - mse: 261.8344\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.6087 - mse: 155.5869\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6668 - mse: 215.1633\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.0468 - mse: 150.9928\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 39.7317 - mse: 2475.0776\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 27.2189 - mse: 1042.4828\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.0353 - mse: 181.3308\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 24.4166 - mse: 837.2488\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.3019 - mse: 524.3480\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.5364 - mse: 848.9193\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.3061 - mse: 316.2499\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.3811 - mse: 150.8313\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.2584 - mse: 757.8696\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.8111 - mse: 214.7289\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.5386 - mse: 438.6382\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.2427 - mse: 93.4057\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 14.4055 - mse: 288.0854\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.8167 - mse: 245.3217\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.4582 - mse: 314.6257\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.2467 - mse: 315.2891\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.3296 - mse: 272.5993\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.3209 - mse: 566.5535\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.4720 - mse: 170.2995\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 29.1772 - mse: 1384.2217\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.2578 - mse: 94.4045\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 29.8922 - mse: 1620.3472\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 54.2504 - mse: 5273.4067\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5899 - mse: 101.4287\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.1833 - mse: 182.2242\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.9573 - mse: 869.8670\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6202 - mse: 243.1982\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.5189 - mse: 660.4364\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.3948 - mse: 150.4475\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.4825 - mse: 270.0062\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.8031 - mse: 139.6790\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.6186 - mse: 400.6650\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.9878 - mse: 180.0287\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.3120 - mse: 115.1649\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.6002 - mse: 110.9967\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 28.0120 - mse: 1258.6671\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.2956 - mse: 147.2471\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.0830 - mse: 289.4816\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.5011 - mse: 256.6292\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.3373 - mse: 407.7532\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5238 - mse: 98.7683\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.7154 - mse: 253.9057\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.5670 - mse: 153.2034\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 30.2257 - mse: 1575.6985\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.7352 - mse: 279.1417\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.4457 - mse: 1072.7356\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.0367 - mse: 1028.7074\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 11.2460 - mse: 171.5487\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.2249 - mse: 218.6440\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.8754 - mse: 107.6232\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.4150 - mse: 255.2669\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.9405 - mse: 141.6514\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 537us/step - loss: 13.5630 - mse: 246.4109\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.8775 - mse: 486.6566\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.7416 - mse: 92.1292\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.1381 - mse: 373.2914\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.7498 - mse: 146.6601\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 22.1831 - mse: 729.0075\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.2709 - mse: 121.2550\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.4682 - mse: 268.9867\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.4343 - mse: 163.1331\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.6187 - mse: 245.7690\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.6233 - mse: 346.7656\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.8532 - mse: 168.3376\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.6254 - mse: 372.3842\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 251us/step - loss: 24.1342 - mse: 916.6349\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.6315 - mse: 149.3768\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.4825 - mse: 189.7122\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.7086 - mse: 432.6884\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.0873 - mse: 96.3651\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 24.0255 - mse: 868.9744\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.8174 - mse: 1110.9153\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.7213 - mse: 172.4500\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.0124 - mse: 211.8800\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.4085 - mse: 394.8098\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 500us/step - loss: 7.2769 - mse: 73.4361\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.9605 - mse: 312.6097\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.2848 - mse: 315.4443\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 19.0979 - mse: 520.7352\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 29.8574 - mse: 1290.3834\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.1967 - mse: 124.4853\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.5458 - mse: 665.3117\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.5927 - mse: 162.0392\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 18.4135 - mse: 464.9257\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.4299 - mse: 82.2258\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.7470 - mse: 446.1800\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.1306 - mse: 164.4273\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 19.4420 - mse: 510.8730\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.1735 - mse: 210.1595\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.5784 - mse: 169.5827\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.8853 - mse: 265.3636\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 250us/step - loss: 20.2151 - mse: 607.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cfb0c0a60>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "model_2.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1333f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFB2F6EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bcd14b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1110053>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=12.497129>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, y_preds_2)\n",
    "mse_2 = mse(y_test, y_preds_2)\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b65a02",
   "metadata": {},
   "source": [
    "**Build model_3**\n",
    "\n",
    "* 2 layers, trained for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42871dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 27.8687 - mae: 27.8687\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.6488 - mae: 16.6488\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.7462 - mae: 26.7462\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 251us/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 29.8228 - mae: 29.8228\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 20.2277 - mae: 20.2277\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.4479 - mae: 11.4479\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.4842 - mae: 17.4842\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.0217 - mae: 7.0217\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.5789 - mae: 23.5789\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.8932 - mae: 16.8932\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.2954 - mae: 9.2954\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.3749 - mae: 25.3749\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.4621 - mae: 13.4621\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.5987 - mae: 14.5987\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.8092 - mae: 17.8092\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.1782 - mae: 17.1782\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 750us/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.3071 - mae: 23.3071\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 750us/step - loss: 9.6144 - mae: 9.6144\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6899 - mae: 10.6899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 8.0355 - mae: 8.0355\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 29.6859 - mae: 29.6859\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.0714 - mae: 8.0714\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 28.3086 - mae: 28.3086\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 32.9014 - mae: 32.9014\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.6291 - mae: 19.6291\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.8056 - mae: 21.8056\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.9812 - mae: 7.9812\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.0585 - mae: 21.0585\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.0107 - mae: 9.0107\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.0502 - mae: 24.0502\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.7537 - mae: 9.7537\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.3052 - mae: 18.3052\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.5833 - mae: 7.5833\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.5755 - mae: 18.5755\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.5360 - mae: 10.5360\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.2694 - mae: 18.2694\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.1658 - mae: 23.1658\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.9181 - mae: 8.9181\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.4732 - mae: 16.4732\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.4208 - mae: 8.4208\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 36.9540 - mae: 36.9540\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.5820 - mae: 25.5820\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.5392 - mae: 9.5392\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 26.6058 - mae: 26.6058\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 8.7248 - mae: 8.7248\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.6172 - mae: 15.6172\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.3065 - mae: 18.3065\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.1994 - mae: 8.1994\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.4964 - mae: 7.4964\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.3374 - mae: 18.3374\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 10.2895 - mae: 10.2895\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 29.6425 - mae: 29.6425\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.4537 - mae: 15.4537\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.0174 - mae: 17.0174\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 32.8218 - mae: 32.8218\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.7038 - mae: 10.7038\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.9054 - mae: 8.9054\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 22.1321 - mae: 22.1321\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.7113 - mae: 11.7113\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.5734 - mae: 21.5734\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.2485 - mae: 19.2485\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.0156 - mae: 11.0156\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.6187 - mae: 9.6187\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.5908 - mae: 21.5908\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 26.2851 - mae: 26.2851\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.8525 - mae: 9.8525\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 500us/step - loss: 22.5631 - mae: 22.5631\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.1499 - mae: 10.1499\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 18.0464 - mae: 18.0464\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 28.8377 - mae: 28.8377\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.5280 - mae: 16.5280\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.2115 - mae: 11.2115\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 27.5839 - mae: 27.5839\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.2680 - mae: 8.2680\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2580 - mae: 9.2580\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.1440 - mae: 18.1440\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.8992 - mae: 7.8992\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.4015 - mae: 17.4015\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.0089 - mae: 11.0089\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.7027 - mae: 11.7027\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 30.4062 - mae: 30.4062\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.5557 - mae: 7.5557\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.9905 - mae: 15.9905\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.5579 - mae: 8.5579\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 28.7339 - mae: 28.7339\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.1689 - mae: 13.1689\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.3101 - mae: 18.3101\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.7376 - mae: 13.7376\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.7104 - mae: 13.7104\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 28.5842 - mae: 28.5842\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.0707 - mae: 7.0707\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 7.0550 - mae: 7.0550\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 22.0067 - mae: 22.0067\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.8443 - mae: 20.8443\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 12.4713 - mae: 12.4713\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 17.9099 - mae: 17.9099\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.7493 - mae: 13.7493\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.7005 - mae: 13.7005\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.4142 - mae: 9.4142\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.9796 - mae: 20.9796\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.5470 - mae: 9.5470\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.7256 - mae: 11.7256\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.3772 - mae: 14.3772\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 14.8579 - mae: 14.8579\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.9706 - mae: 14.9706\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 17.8998 - mae: 17.8998\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.8327 - mae: 9.8327\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.3352 - mae: 18.3352\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.0383 - mae: 15.0383\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.5874 - mae: 14.5874\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 23.3015 - mae: 23.3015\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.3613 - mae: 13.3613\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.8517 - mae: 9.8517\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.5451 - mae: 12.5451\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.1130 - mae: 7.1130\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 35.4567 - mae: 35.4567\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 34.8634 - mae: 34.8634\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.7004 - mae: 14.7004\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.7196 - mae: 16.7196\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.9329 - mae: 15.9329\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.1644 - mae: 16.1644\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.9324 - mae: 13.9324\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.0504 - mae: 18.0504\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.6120 - mae: 15.6120\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 21.2041 - mae: 21.2041\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.2732 - mae: 25.2732\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.3176 - mae: 16.3176\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.2729 - mae: 7.2729\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.9688 - mae: 16.9688\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 7.1225 - mae: 7.1225\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.2058 - mae: 9.2058\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.0961 - mae: 8.0961\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.8627 - mae: 8.8627\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.7886 - mae: 8.7886\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.8161 - mae: 18.8161\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 14.0531 - mae: 14.0531\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.6831 - mae: 14.6831\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.8045 - mae: 15.8045\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.6810 - mae: 17.6810\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.5070 - mae: 14.5070\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.2322 - mae: 23.2322\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.3009 - mae: 9.3009\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 36.6568 - mae: 36.6568\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 500us/step - loss: 21.8205 - mae: 21.8205\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.2792 - mae: 7.2792\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.7126 - mae: 24.7126\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.4220 - mae: 12.4220\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.5823 - mae: 10.5823\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.4883 - mae: 14.4883\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 8.6132 - mae: 8.6132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 43.0580 - mae: 43.0580\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 18.4611 - mae: 18.4611\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 6.8820 - mae: 6.8820\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.7211 - mae: 13.7211\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.0154 - mae: 21.0154\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.3730 - mae: 19.3730\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.4735 - mae: 11.4735\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.5302 - mae: 7.5302\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.6453 - mae: 21.6453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 33.1785 - mae: 33.1785\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.1012 - mae: 12.1012\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 26.1372 - mae: 26.1372\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.1751 - mae: 12.1751\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 750us/step - loss: 13.3272 - mae: 13.3272\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 29.3775 - mae: 29.3775\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 7.3329 - mae: 7.3329\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 31.1362 - mae: 31.1362\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.3015 - mae: 12.3015\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.4103 - mae: 16.4103\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.9118 - mae: 21.9118\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 22.1500 - mae: 22.1500\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.7429 - mae: 7.7429\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.1429 - mae: 8.1429\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 24.9434 - mae: 24.9434\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.6958 - mae: 13.6958\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 6.8926 - mae: 6.8926\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.5352 - mae: 24.5352\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.1721 - mae: 20.1721\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.9658 - mae: 11.9658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.5391 - mae: 16.5391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 16.8017 - mae: 16.8017\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.2711 - mae: 15.2711\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 22.7179 - mae: 22.7179\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.9234 - mae: 17.9234\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 6.1742 - mae: 6.1742\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.9440 - mae: 10.9440\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.1530 - mae: 23.1530\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 17.7331 - mae: 17.7331\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 6.9824 - mae: 6.9824\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.1857 - mae: 25.1857\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 8.9025 - mae: 8.9025\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.7668 - mae: 17.7668\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 249us/step - loss: 11.0002 - mae: 11.0002\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.9191 - mae: 12.9191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.6094 - mae: 13.6094\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.4404 - mae: 7.4404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.7099 - mae: 10.7099\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.2814 - mae: 13.2814\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 29.9763 - mae: 29.9763\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.9106 - mae: 9.9106\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 23.7669 - mae: 23.7669\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.3936 - mae: 16.3936\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.0758 - mae: 21.0758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.9367 - mae: 7.9367\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.9731 - mae: 17.9731\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.2375 - mae: 10.2375\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.3338 - mae: 8.3338\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 5.0621 - mae: 5.0621\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 23.5109 - mae: 23.5109\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 16.3863 - mae: 16.3863\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.5019 - mae: 7.5019\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 20.0573 - mae: 20.0573\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.7661 - mae: 13.7661\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.8282 - mae: 16.8282\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.0514 - mae: 7.0514\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 21.4846 - mae: 21.4846\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.2880 - mae: 12.2880\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.8117 - mae: 11.8117\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.4833 - mae: 12.4833\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 32.2171 - mae: 32.2171\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 250us/step - loss: 10.4477 - mae: 10.4477\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 19.6832 - mae: 19.6832\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 35.0762 - mae: 35.0762\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.4192 - mae: 10.4192\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.7625 - mae: 9.7625\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.9500 - mae: 11.9500\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.3943 - mae: 9.3943\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 249us/step - loss: 37.4876 - mae: 37.4876\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.8748 - mae: 12.8748\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 8.1960 - mae: 8.1960\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.5568 - mae: 13.5568\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 32.9626 - mae: 32.9626\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 14.2040 - mae: 14.2040\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.9196 - mae: 15.9196\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.0878 - mae: 19.0878\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 34.1178 - mae: 34.1178\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.6798 - mae: 7.6798\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.2287 - mae: 25.2287\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 22.6759 - mae: 22.6759\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.8765 - mae: 8.8765\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.4709 - mae: 21.4709\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 20.6073 - mae: 20.6073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.0611 - mae: 7.0611\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.8117 - mae: 25.8117\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 32.2247 - mae: 32.2247\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.0205 - mae: 10.0205\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 30.4171 - mae: 30.4171\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.5020 - mae: 10.5020\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.9909 - mae: 14.9909\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.6580 - mae: 14.6580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 23.3672 - mae: 23.3672\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.1025 - mae: 13.1025\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2586 - mae: 9.2586\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.0041 - mae: 13.0041\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 14.8863 - mae: 14.8863\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.7932 - mae: 14.7932\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.2751 - mae: 16.2751\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.8307 - mae: 20.8307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 33.5318 - mae: 33.5318\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.2166 - mae: 8.2166\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.0960 - mae: 13.0960\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.3999 - mae: 8.3999\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.9390 - mae: 10.9390\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.7654 - mae: 19.7654\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 24.8625 - mae: 24.8625\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.7422 - mae: 8.7422\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 5.9488 - mae: 5.9488\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.4401 - mae: 24.4401\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 5.9771 - mae: 5.9771\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.3250 - mae: 16.3250\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 6.0917 - mae: 6.0917\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.9601 - mae: 14.9601\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.6462 - mae: 7.6462\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 14.5992 - mae: 14.5992\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.3166 - mae: 11.3166\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.9080 - mae: 21.9080\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.8654 - mae: 14.8654\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.4970 - mae: 8.4970\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 10.3957 - mae: 10.3957\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.2556 - mae: 10.2556\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 6.3392 - mae: 6.3392\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.4602 - mae: 17.4602\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.4627 - mae: 11.4627\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.7294 - mae: 20.7294\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 31.3339 - mae: 31.3339\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2542 - mae: 9.2542\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.8621 - mae: 14.8621\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 21.7182 - mae: 21.7182\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.6615 - mae: 12.6615\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 6.0687 - mae: 6.0687\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.2201 - mae: 13.2201\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 27.4244 - mae: 27.4244\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 12.8230 - mae: 12.8230\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 24.7510 - mae: 24.7510\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 501us/step - loss: 17.3753 - mae: 17.3753\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 7.8241 - mae: 7.8241\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 25.3789 - mae: 25.3789\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.1031 - mae: 15.1031\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 7.1643 - mae: 7.1643\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 20.3318 - mae: 20.3318\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 6.3283 - mae: 6.3283\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.9962 - mae: 12.9962\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.7869 - mae: 10.7869\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.4007 - mae: 11.4007\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6153 - mae: 10.6153\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.4582 - mae: 11.4582\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.3850 - mae: 11.3850\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 30.3986 - mae: 30.3986\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.5052 - mae: 10.5052\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 28.8810 - mae: 28.8810\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.5916 - mae: 8.5916\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.7378 - mae: 12.7378\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 33.6754 - mae: 33.6754\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.0962 - mae: 15.0962\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.4813 - mae: 17.4813\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 22.3049 - mae: 22.3049\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 23.5841 - mae: 23.5841\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 11.0008 - mae: 11.0008\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.9175 - mae: 14.9175\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 17.9979 - mae: 17.9979\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 10.0527 - mae: 10.0527\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.0052 - mae: 14.0052\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 16.7782 - mae: 16.7782\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 14.2937 - mae: 14.2937\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 30.6192 - mae: 30.6192\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 7.6541 - mae: 7.6541\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 28.1428 - mae: 28.1428\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.0017 - mae: 8.0017\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 10.3933 - mae: 10.3933\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.0242 - mae: 15.0242\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 16.5653 - mae: 16.5653\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 26.8566 - mae: 26.8566\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.4852 - mae: 12.4852\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.3186 - mae: 13.3186\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 29.5524 - mae: 29.5524\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 3.4664 - mae: 3.4664\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 15.2136 - mae: 15.2136\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 20.8327 - mae: 20.8327\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 30.5108 - mae: 30.5108\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 11.0598 - mae: 11.0598\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.8372 - mae: 12.8372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 3.2398 - mae: 3.2398\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.6964 - mae: 16.6964\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.3883 - mae: 13.3883\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.2771 - mae: 15.2771\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.7448 - mae: 11.7448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 16.4113 - mae: 16.4113\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 251us/step - loss: 13.8785 - mae: 13.8785\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.6702 - mae: 30.6702\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.7384 - mae: 10.7384\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.9051 - mae: 17.9051\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.8094 - mae: 15.8094\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.3054 - mae: 21.3054\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 25.3845 - mae: 25.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.9816 - mae: 23.9816\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 5.7734 - mae: 5.7734\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 20.0011 - mae: 20.0011\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.0419 - mae: 14.0419\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 30.6088 - mae: 30.6088\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.9409 - mae: 11.9409\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.6139 - mae: 23.6139\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 20.5365 - mae: 20.5365\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 4.9942 - mae: 4.9942\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 12.7987 - mae: 12.7987\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 13.3772 - mae: 13.3772\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 12.6727 - mae: 12.6727\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 17.6192 - mae: 17.6192\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.5629 - mae: 23.5629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.3755 - mae: 9.3755\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 250us/step - loss: 14.6316 - mae: 14.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cfc41eca0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c16ed2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFC388B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot some predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35a4631a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 evaluation metrics\n",
    "mae_3 = mae(y_test, y_preds_3)\n",
    "mse_3 = mse(y_test, y_preds_3)\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a169f",
   "metadata": {},
   "source": [
    " **Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8691c1",
   "metadata": {},
   "source": [
    "## Comparing the results of our experiments\n",
    "\n",
    "We've run a few experiments now; let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19a85b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>18.745327</td>\n",
       "      <td>353.573364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.111005</td>\n",
       "      <td>12.497129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.713615</td>\n",
       "      <td>4808.027344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1  18.745327   353.573364\n",
       "1  model_2   3.111005    12.497129\n",
       "2  model_3  68.713615  4808.027344"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare our model's results using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                [\"model_2\",mae_2.numpy(),mse_2.numpy()],\n",
    "                [\"model_3\",mae_3.numpy(),mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\",\"mae\",\"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2efd89",
   "metadata": {},
   "source": [
    "It looks like model_2 performed the best..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67712c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3900ac",
   "metadata": {},
   "source": [
    "> **Note:** One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, you will get closer to figuring out what does work. Remember, the machine learning practioner's motto: \"experiment, experiment, experiment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592244e9",
   "metadata": {},
   "source": [
    "## Tracking your experiments\n",
    "\n",
    "One really good habit in machine learning modeling is to track the results of your experiments.\n",
    "\n",
    "And when doing so, it can be tedious if you're running lots of experiments.\n",
    "\n",
    "Luckily, there are tools to help us!\n",
    "\n",
    "**Resource:** As you build more models, you'll want to look into using:\n",
    "\n",
    "* TensorBoard - a component of the TensorFlow library to help track modeling experiments (we'll see this one later).\n",
    "* Weights & Biases - a tool for tracking all kinds of machine learning experiments (plugs straight into TensorBoard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75428e65",
   "metadata": {},
   "source": [
    "## Saving our models\n",
    "\n",
    "Saving models allows us to use them outside of Jupyter Notebook (or wherever they were trained) such as in a web application or an app.\n",
    "\n",
    "There are two main formats we can save our models to:\n",
    "\n",
    "1. The SavedModel format\n",
    "2. The HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d12f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bliu0\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\bliu0\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model using the SavedModel format \n",
    "model_2.save(\"best_model_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "784bc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using the HDF5 format\n",
    "model_2.save(\"best_model_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8fb4b",
   "metadata": {},
   "source": [
    "## Loading in a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f295d8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load in the SavedModel format\n",
    "loaded_SavedModel_format = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
    "loaded_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ea735ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFC86ADC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with SavedModel format model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
    "model_2_preds == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b788573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load in a model using the .h5 format\n",
    "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bed1421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9516fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015CFC879B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if loaded .h5 model predictions math model_2\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3c1a804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the MAE of model_2 preds and loaded_SavedModel_preds\n",
    "mae(y_true=y_test, y_pred=model_2_preds) == mae(y_true=y_test, y_pred=loaded_SavedModel_format_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7d1df",
   "metadata": {},
   "source": [
    "## Download a model (or any other file) from Google Colab\n",
    "\n",
    "If you want to download your files from Google Colab:\n",
    "\n",
    "1. You can go to the \"files\" tab and right click on the file you're after and click \"download.\"\n",
    "2. Use code (see the cell below)\n",
    "3. Save it to Google Drive by connecting Google Drive and copying it there (see 2nd code cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd118410",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-42afc3a00a96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Download a file from Google Colab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/best_model_HDF5_format.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Download a file from Google Colab\n",
    "from google.colab import files\n",
    "files.download(\"/content/best_model_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a0a31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
    "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/FOLDER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fcacc262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/FOLDER_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1e550",
   "metadata": {},
   "source": [
    "## A larger example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f10a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e8f2b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the insurancec dataset\n",
    "insurance=pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e68a53b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       yes\n",
       " 1        no\n",
       " 2        no\n",
       " 3        no\n",
       " 4        no\n",
       "        ... \n",
       " 1333     no\n",
       " 1334     no\n",
       " 1335     no\n",
       " 1336     no\n",
       " 1337    yes\n",
       " Name: smoker, Length: 1338, dtype: object,\n",
       " 0       19\n",
       " 1       18\n",
       " 2       28\n",
       " 3       33\n",
       " 4       32\n",
       "         ..\n",
       " 1333    50\n",
       " 1334    18\n",
       " 1335    18\n",
       " 1336    21\n",
       " 1337    61\n",
       " Name: age, Length: 1338, dtype: int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance[\"smoker\"], insurance[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fdf2dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try one-hot encode our DataFrame so it's all numbers\n",
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e96d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y values (features and labels)\n",
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "y = insurance_one_hot[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e7c6658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fde5c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d732163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efcf81eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267.6"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*1338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15327703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.950</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>39</td>\n",
       "      <td>23.870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>58</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>37</td>\n",
       "      <td>47.600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>55</td>\n",
       "      <td>29.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.950         2           1         0          1           0   \n",
       "1285   47  24.320         0           1         0          1           0   \n",
       "1142   52  24.860         0           1         0          1           0   \n",
       "969    39  34.320         5           1         0          1           0   \n",
       "486    54  21.470         3           1         0          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1095   18  31.350         4           1         0          1           0   \n",
       "1130   39  23.870         5           1         0          1           0   \n",
       "1294   58  25.175         0           0         1          1           0   \n",
       "860    37  47.600         2           1         0          0           1   \n",
       "1126   55  29.900         0           0         1          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1095                 1                 0                 0                 0  \n",
       "1130                 0                 0                 1                 0  \n",
       "1294                 1                 0                 0                 0  \n",
       "860                  0                 0                 0                 1  \n",
       "1126                 0                 0                 0                 1  \n",
       "\n",
       "[1070 rows x 11 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3bc3915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_50 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 353us/step - loss: 8637.0996 - mae: 8637.0996\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 324us/step - loss: 7886.7759 - mae: 7886.7759\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7792.0220 - mae: 7792.0220\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 338us/step - loss: 7748.3892 - mae: 7748.3892\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7595.3940 - mae: 7595.3940\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7589.9849 - mae: 7589.9849\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7698.5586 - mae: 7698.5586\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7496.7778 - mae: 7496.7778\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7493.1733 - mae: 7493.1733\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7706.9033 - mae: 7706.9033\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7393.5322 - mae: 7393.5322\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7780.6982 - mae: 7780.6982\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7578.5093 - mae: 7578.5093\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7750.8350 - mae: 7750.8350\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7739.2134 - mae: 7739.2134\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7875.0635 - mae: 7875.0635\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7466.6768 - mae: 7466.6768\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7941.2310 - mae: 7941.2310\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7640.2725 - mae: 7640.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7539.2656 - mae: 7539.2656\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7619.9653 - mae: 7619.9653\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7644.1709 - mae: 7644.1709\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7709.0361 - mae: 7709.0361\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7366.8657 - mae: 7366.8657\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7444.3135 - mae: 7444.3135\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7686.3862 - mae: 7686.3862\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7548.0981 - mae: 7548.0981\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7501.5532 - mae: 7501.5532\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7363.4155 - mae: 7363.4155\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7295.4468 - mae: 7295.4468\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7569.8813 - mae: 7569.8813\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7548.2002 - mae: 7548.2002\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7529.7739 - mae: 7529.7739\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7467.3232 - mae: 7467.3232\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7635.9282 - mae: 7635.9282\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7536.8403 - mae: 7536.8403\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 4568.1855 - mae: 4568.185 - 0s 368us/step - loss: 7616.5845 - mae: 7616.5845\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7439.4932 - mae: 7439.4932\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7538.0151 - mae: 7538.0151\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7415.1460 - mae: 7415.1460\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7509.9829 - mae: 7509.9829\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7541.1123 - mae: 7541.1123\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7467.8633 - mae: 7467.8633\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7389.3545 - mae: 7389.3545\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7499.7749 - mae: 7499.7749\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7429.5859 - mae: 7429.5859\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7313.4014 - mae: 7313.4014\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7542.2661 - mae: 7542.2661\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7576.9277 - mae: 7576.9277\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7546.4058 - mae: 7546.4058\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7351.2261 - mae: 7351.2261\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7302.1436 - mae: 7302.1436\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7393.0879 - mae: 7393.0879\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7442.2881 - mae: 7442.2881\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 324us/step - loss: 7492.6782 - mae: 7492.6782\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7561.9165 - mae: 7561.9165\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7340.5142 - mae: 7340.5142\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7496.0854 - mae: 7496.0854\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7617.0298 - mae: 7617.0298\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7084.2744 - mae: 7084.2744\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7240.4907 - mae: 7240.4907\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 324us/step - loss: 7283.4888 - mae: 7283.4888\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7335.5063 - mae: 7335.5063\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7275.6392 - mae: 7275.6392\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 324us/step - loss: 7313.1855 - mae: 7313.1855\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7485.7578 - mae: 7485.7578\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7352.2798 - mae: 7352.2798\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7520.5703 - mae: 7520.5703\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7279.3779 - mae: 7279.3779\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7273.8477 - mae: 7273.8477\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7176.5210 - mae: 7176.5210\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7425.6294 - mae: 7425.6294\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7403.1289 - mae: 7403.1289\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7356.0088 - mae: 7356.0088\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7484.7271 - mae: 7484.7271\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7134.1558 - mae: 7134.1558\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7083.4351 - mae: 7083.4351\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 324us/step - loss: 7210.9541 - mae: 7210.9541\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7395.6807 - mae: 7395.6807\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7328.0884 - mae: 7328.0884\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7230.4380 - mae: 7230.4380\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 353us/step - loss: 7261.3936 - mae: 7261.3936\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7342.5684 - mae: 7342.5684\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 339us/step - loss: 7106.1709 - mae: 7106.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c82dfef40>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a neural network (sort of like model_2 above)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(loss=tf.keras.losses.mae,\n",
    "                       optimizer=tf.keras.optimizers.SGD(),\n",
    "                       metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50adb96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 389us/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d28bdc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364485)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median(), y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c7135",
   "metadata": {},
   "source": [
    "Right now it looks like our model isn't performing too well... let's try and improve it!\n",
    "\n",
    "To (try to) improve our model, we'll run 2 experiments:\n",
    "1. Add an extra layer with more hidden units and use the Adam optimizer\n",
    "2. Same as above but train for train for longer (200 epochs)\n",
    "3. (insert your own experiment here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2132899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_71 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 442us/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 11116.2930 - mae: 11116.293 - 0s 427us/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6530.0444 - mae: 6530.0444\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 603us/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 5868.2217 - mae: 5868.221 - 0s 412us/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 442us/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6059.4873 - mae: 6059.4873\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5995.2168 - mae: 5995.2168\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5834.3076 - mae: 5834.3076\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5523.6191 - mae: 5523.6191\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5059.8643 - mae: 5059.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c864734c0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3f13ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 389us/step - loss: 4924.3477 - mae: 4924.3477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4924.34765625, 4924.34765625]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the larger model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0c959af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 445us/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66d988bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_83 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 427us/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 648us/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 500us/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 7967.4492 - mae: 7967.449 - 0s 427us/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6530.0444 - mae: 6530.0444\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 427us/step - loss: 6059.4873 - mae: 6059.4873\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5995.2168 - mae: 5995.2168\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5834.3076 - mae: 5834.3076\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5523.6191 - mae: 5523.6191\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5059.8643 - mae: 5059.8643\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 4987.6191 - mae: 4987.6191\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 4915.2910 - mae: 4915.2910\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4847.3604 - mae: 4847.3604\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 4768.0151 - mae: 4768.0151\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4683.4727 - mae: 4683.4727\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 4600.5054 - mae: 4600.5054\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4513.1436 - mae: 4513.1436\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4422.2988 - mae: 4422.2988\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 4339.9595 - mae: 4339.9595\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4254.3916 - mae: 4254.3916\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 4173.1797 - mae: 4173.1797\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 4102.2944 - mae: 4102.2944\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4031.9590 - mae: 4031.9590\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 383us/step - loss: 3986.0220 - mae: 3986.0220\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3943.2346 - mae: 3943.2346\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3918.8977 - mae: 3918.8977\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3895.5610 - mae: 3895.5610\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3869.5679 - mae: 3869.5679\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3850.2136 - mae: 3850.2136\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3834.7349 - mae: 3834.7349\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3827.0952 - mae: 3827.0952\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3821.6382 - mae: 3821.6382\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3813.8315 - mae: 3813.8315\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3805.7305 - mae: 3805.7305\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3794.7092 - mae: 3794.7092\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3804.4946 - mae: 3804.4946\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3796.0596 - mae: 3796.0596\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3791.0420 - mae: 3791.0420\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3800.0696 - mae: 3800.0696\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3788.5005 - mae: 3788.5005\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3780.8442 - mae: 3780.8442\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3774.5413 - mae: 3774.5413\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3771.0156 - mae: 3771.0156\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3769.3762 - mae: 3769.3762\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3766.7610 - mae: 3766.7610\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3765.5510 - mae: 3765.5510\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3774.5032 - mae: 3774.5032\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3785.3901 - mae: 3785.3901\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3761.1304 - mae: 3761.1304\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3764.1753 - mae: 3764.1753\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3763.9250 - mae: 3763.9250\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3762.7959 - mae: 3762.7959\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3754.4397 - mae: 3754.4397\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3750.3350 - mae: 3750.3350\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3750.4006 - mae: 3750.4006\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3755.4736 - mae: 3755.4736\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3750.3223 - mae: 3750.3223\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3758.1089 - mae: 3758.1089\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3743.4863 - mae: 3743.4863\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 383us/step - loss: 3738.5342 - mae: 3738.5342\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3740.1384 - mae: 3740.1384\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 412us/step - loss: 3742.4954 - mae: 3742.4954\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3744.4399 - mae: 3744.4399\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3737.1826 - mae: 3737.1826\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3737.6541 - mae: 3737.6541\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3737.1667 - mae: 3737.1667\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3733.1101 - mae: 3733.1101\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3729.5808 - mae: 3729.5808\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3725.9050 - mae: 3725.9050\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3733.2822 - mae: 3733.2822\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3728.2559 - mae: 3728.2559\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3724.5825 - mae: 3724.5825\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3723.0806 - mae: 3723.0806\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3726.9473 - mae: 3726.9473\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3716.5427 - mae: 3716.5427\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3721.9155 - mae: 3721.9155\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3721.1814 - mae: 3721.1814\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3715.2458 - mae: 3715.2458\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3713.9756 - mae: 3713.9756\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3707.9919 - mae: 3707.9919\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3707.4158 - mae: 3707.4158\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3710.6831 - mae: 3710.6831\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3703.3616 - mae: 3703.3616\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3710.9385 - mae: 3710.9385\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3713.0417 - mae: 3713.0417\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3705.0571 - mae: 3705.0571\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3698.9333 - mae: 3698.9333\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3697.9985 - mae: 3697.9985\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 442us/step - loss: 3704.9150 - mae: 3704.9150\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3710.3679 - mae: 3710.3679\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3696.6484 - mae: 3696.6484\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3692.7334 - mae: 3692.7334\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3691.1655 - mae: 3691.1655\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3699.2437 - mae: 3699.2437\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3693.2483 - mae: 3693.2483\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3696.1389 - mae: 3696.1389\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3687.8640 - mae: 3687.8640\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3693.3562 - mae: 3693.3562\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3682.7324 - mae: 3682.7324\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3683.2891 - mae: 3683.2891\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3697.6533 - mae: 3697.6533\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3684.6660 - mae: 3684.6660\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 471us/step - loss: 3675.5154 - mae: 3675.5154\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3676.3921 - mae: 3676.3921\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3672.8450 - mae: 3672.8450\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3682.0286 - mae: 3682.0286\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3665.7961 - mae: 3665.7961\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3671.7419 - mae: 3671.7419\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3680.5464 - mae: 3680.5464\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3665.6401 - mae: 3665.6401\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model (same as above)\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "003a8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 389us/step - loss: 3491.2961 - mae: 3491.2961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3491.296142578125, 3491.296142578125]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e8f50503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 389us/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f3bd33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve or a training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2830c8",
   "metadata": {},
   "source": [
    ">  **Question:** How long should you train for?\n",
    "\n",
    "It depends. Really... it depends on the problem you're working on. However, many people have asked this question before... so TensorFlow has a solution! It's called the [EarlyStopping Callback] (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), which is a TensorFlow component you can add to your model to stop training once it stops improving a certain metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505249d4",
   "metadata": {},
   "source": [
    "## Preprocessing data (normalization and standardization)\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization.\n",
    "\n",
    "If you're not sure on which to use, you could try both and see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0975815b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataframe\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498b58d",
   "metadata": {},
   "source": [
    "To prepare our data, we can borrow a few classes from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "da7ebc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7726bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does our data look like now?\n",
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0ca76bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "88c2bc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f9ee9",
   "metadata": {},
   "source": [
    "Beautiful! Our data has been normalized and one hot encoded. Now let's buildl a neural network model and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ade1df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 13333.4785 - mae: 13333.4785\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 13189.5830 - mae: 13189.5830\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 9482.7422 - mae: 9482.7422\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 8081.9775 - mae: 8081.9775\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7697.9595 - mae: 7697.9595\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7656.0273 - mae: 7656.0273\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7527.4175 - mae: 7527.4175\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7483.5942 - mae: 7483.5942\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7439.4424 - mae: 7439.4424\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7395.0552 - mae: 7395.0552\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7346.8120 - mae: 7346.8120\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7199.5303 - mae: 7199.5303\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7148.4814 - mae: 7148.4814\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 559us/step - loss: 7093.6650 - mae: 7093.6650\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7038.1797 - mae: 7038.1797\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6981.7393 - mae: 6981.7393\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6922.7847 - mae: 6922.7847\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6860.1724 - mae: 6860.1724\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6793.7979 - mae: 6793.7979\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: 6428.6021 - mae: 6428.6021\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 500us/step - loss: 6342.7100 - mae: 6342.7100\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5862.5625 - mae: 5862.5625\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5753.9531 - mae: 5753.9531\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5638.0947 - mae: 5638.0947\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 486us/step - loss: 5519.8691 - mae: 5519.8691\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5277.3501 - mae: 5277.3501\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 5149.7642 - mae: 5149.7642\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 5019.3540 - mae: 5019.3540\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 486us/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 4629.4370 - mae: 4629.4370\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 486us/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 4089.5725 - mae: 4089.5725\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 4003.3901 - mae: 4003.3901\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 471us/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3813.7146 - mae: 3813.7146\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3773.0317 - mae: 3773.0317\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 3744.2000 - mae: 3744.2000\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 3719.6870 - mae: 3719.6870\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 427us/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 3676.9766 - mae: 3676.9766\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 3673.9495 - mae: 3673.9495\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3664.5757 - mae: 3664.5757\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3661.8562 - mae: 3661.8562\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3660.3047 - mae: 3660.3047\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3655.2200 - mae: 3655.2200\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 3652.0200 - mae: 3652.0200\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 456us/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3648.4463 - mae: 3648.4463\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3644.4375 - mae: 3644.4375\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3645.8770 - mae: 3645.8770\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 397us/step - loss: 3642.2573 - mae: 3642.2573\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3640.1187 - mae: 3640.1187\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3638.0649 - mae: 3638.0649\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 427us/step - loss: 3637.2051 - mae: 3637.2051\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 412us/step - loss: 3636.1707 - mae: 3636.1707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c89481f40>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a neural network model to fit on our normalized data\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f06644bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 389us/step - loss: 3438.7844 - mae: 3438.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3438.784423828125, 3438.784423828125]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our insurance model trained on normalized data\n",
    "insurance_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insurance model 2 results\n",
    "# 9/9 [==============================] - 0s 389us/step - loss: 4924.3477 - mae: 4924.3477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a9be274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"age\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ece0d13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"bmi\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d2c952f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"children\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a67dde",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
